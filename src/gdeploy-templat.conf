# A sample configuration file to setup ROBO

[hosts]
10.70.41.161
10.70.41.245
10.70.43.128

[disktype]
raid6

[diskcount]
4

[stripesize]
256

[yum1]
action=install
gpgcheck=no
# Repos should be an url; eg: http://repo-pointing-glusterfs-builds
repos=http://resources.ovirt.org/pub/ovirt-master-snapshot-static/rpm/el7Server/,http://resources.ovirt.org/pub/ovirt-master-snapshot/rpm/el7Server/,http://mirror.centos.org/centos/7/storage/x86_64/gluster-3.8/
packages=vdsm,vdsm-gluster,ovirt-hosted-engine-setup,screen,gluster-nagios-addons,xauth
update=yes

# Setup ntp on the servers before any other operations are done
# Disable the existing public servers
[shell1]
action=execute
command=sed -i 's/^\(server .*iburst\)/#\1/' /etc/ntp.conf

# Add custom server
[update-file1]
action=add
dest=/etc/ntp.conf
line=server clock.redhat.com iburst

[service1]
action=enable
service=ntpd

[service2]
action=restart
service=ntpd

[shell2]
action=execute
command=vdsm-tool configure --force

[service3]
action=start
service=vdsmd

# Disable multipath
[script1]
action=execute
file=/usr/share/ansible/gdeploy/scripts/disable-multipath.sh

[pv]
action=create
devices=vdb

[vg1]
action=create
vgname=RHGS_vg1
pvname=vdb

[lv1]
action=create
vgname=RHGS_vg1
lvname=engine_lv
lvtype=thick
size=5GB
mount=/rhgs/brick1

[lv2]
action=create
vgname=RHGS_vg1
poolname=lvthinpool
lvtype=thinpool
poolmetadatasize=10MB
chunksize=1024k
size=1GB

[lv3]
action=create
lvname=lv_vmaddldisks
poolname=lvthinpool
vgname=RHGS_vg1
lvtype=thinlv
mount=/rhgs/brick2
virtualsize=5GB

[lv4]
action=create
lvname=lv_vmrootdisks
poolname=lvthinpool
vgname=RHGS_vg1
size=19GB
lvtype=thinlv
mount=/rhgs/brick3
virtualsize=4GB

[selinux]
yes

[vg2]
action=extend
vgname=RHGS_vg1
pvname=vdc

[lv5]
action=setup-cache
ssd=sdc
vgname=RHGS_vg1
poolname=lvthinpool
cache_meta_lv=lvcachemeta
cache_lv=lvcache
cache_meta_lvsize=1GB
cache_lvsize=5GB

[service4]
action=stop
service=NetworkManager

[service5]
action=disable
service=NetworkManager

[service6]
action=restart
service=glusterd

[firewalld]
action=add
ports=111/tcp,2049/tcp,54321/tcp,5900/tcp,5900-6923/tcp,5666/tcp,16514/tcp
services=glusterfs

[selinux]
yes

[update-file2]
action=edit
dest=/etc/nagios/nrpe.cfg
replace=allowed_hosts
line=allowed_hosts=host.redhat.com

[service7]
action=restart
service=nrpe

[script2]
action=execute
file=/usr/share/ansible/gdeploy/scripts/disable-gluster-hooks.sh

[volume1]
action=create
volname=engine
transport=tcp
replica=yes
replica_count=3
key=group,storage.owner-uid,storage.owner-gid,features.shard,features.shard-block-size,performance.low-prio-threads,cluster.data-self-heal-algorithm
value=virt,36,36,on,512MB,32,full
brick_dirs=/rhgs/brick1/engine

[volume2]
action=create
volname=vmstore
transport=tcp
replica=yes
replica_count=3
key=group,storage.owner-uid,storage.owner-gid,features.shard,features.shard-block-size,performance.low-prio-threads,cluster.data-self-heal-algorithm
value=virt,36,36,on,512MB,32,full
brick_dirs=/rhgs/brick2/vmstore

[volume3]
action=create
volname=data
transport=tcp
replica=yes
replica_count=3
key=group,storage.owner-uid,storage.owner-gid,features.shard,features.shard-block-size,performance.low-prio-threads,cluster.data-self-heal-algorithm
value=virt,36,36,on,512MB,32,full
brick_dirs=/rhgs/brick3/data

[yum2:host1]
action=install
gpgcheck=no
packages=rhevm-appliance

# [shell3]
# action=execute
# command=reboot
